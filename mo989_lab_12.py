# -*- coding: utf-8 -*-
"""mo989_Lab 12

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/185tdoKVL6F0IfZIr6bitXOJAgLJxyEGr

# Lab 12 - Pivoting and unpivoting

This lab focuses on data transformation using pivoting and unpivoting operations with the polars library.

## Load your packages

You will need the `polars` package for this assignment. We'll also use `numpy` for some calculations.
"""

# Import required packages
import polars as pl

"""# Question 1: Pivot US Economic Indicator Data

## 1a. Pivot data

Load the `economics_long.csv` dataset from the `data/` folder. You'll notice that in the `economics_long` dataset's `value` column, there are different types of measurements. Transform this dataset so that the unique values for the `variable` field become columns of their own.

**Please write code below to pivot the data. The output should be a DataFrame. You must "pivot" the data to receive full credit on this question.**
"""

# Load economics_long data
economics_long = pl.read_csv("https://raw.githubusercontent.com/philhetzel/opan5510-class12/refs/heads/main/data/economics_long.csv")

# YOUR CODE HERE: Pivot the data so that each unique value in 'variable' becomes its own column
# Hint: Use the pivot() function
# The index should be 'date', columns should come from 'variable', and values from 'value'

import polars as pl

# Load the dataset
# economics_long = pl.read_csv("data/economics_long.csv") # This line caused the error

# Pivot the data
economics_wide = economics_long.pivot(
    values="value",        # column containing the values
    index="date",          # column to keep as rows
    columns="variable"     # column whose unique values become new columns
)

economics_wide

"""## 1b. Calculate median unemployment for 2010-01-01 and beyond

Next, compute the median unemployment metric (as defined by `unemploy`) for 2010-01-01 and beyond.

**Please write code below. The output should show the median value. You must use the dataframe created in 1a.**
"""

import polars as pl

# Ensure 'date' column is a Date type
# The 'date' column is already of type Date, so this conversion is not needed.
# economics_wide = economics_wide.with_columns(
#     pl.col("date").str.strptime(pl.Date)
# )

# Create a Polars date literal for comparison
start_date = pl.lit("2010-01-01").str.strptime(pl.Date)

# Filter for dates >= 2010-01-01
filtered_economics = economics_wide.filter(pl.col("date") >= start_date)

# Calculate median unemployment
median_unemploy = filtered_economics["unemploy"].median()

print(f"The median unemployment for 2010-01-01 and beyond is: {median_unemploy}")

"""### Answer: The median unemployment for 2010-01-01 and beyond is:12471

# Question 2: Air Passenger data

## 2a. Unpivot data

The `AirPassengers` dataset is wide, which makes it difficult to aggregate. Transform the `AirPassengers` dataset from wide to long. The resulting dataset should have three columns: one column representing year, one column representing month, and one column representing the number of air passengers.

**Please write code below to unpivot the data. The output should be a DataFrame. You must "unpivot" the data to receive full credit on this question.**
"""

# Load AirPassengers data
# Note: You may need to specify separator if it's not comma-separated
air_passengers = pl.read_csv("https://raw.githubusercontent.com/philhetzel/opan5510-class12/refs/heads/main/data/AirPassengers.txt", separator="\t")  # Adjust separator if needed

# Display the original data structure
print("Original data shape:", air_passengers.shape)
print("\nFirst few rows:")
print(air_passengers.head())

# YOUR CODE HERE: Transform from wide to long format
# Hint: Use unpivot() function to unpivot the data
# You'll need to identify which columns represent months and unpivot them
# Use 'index' for columns to keep and 'on' for columns to unpivot

# Get the month columns to unpivot
month_cols = [col for col in air_passengers.columns if col != 'Year'] # Corrected column name

# Unpivot the data
air_passengers_long = air_passengers.unpivot(
    index="Year",      # column to keep as rows # Corrected column name
    on=month_cols,     # columns to unpivot
    variable_name="month", # name for the new column containing the original column names
    value_name="passengers" # name for the new column containing the values
)

# Display the unpivoted dataframe
air_passengers_long

"""## 2b. Find the standard deviation between 1955 and 1960

Next, compute the standard deviation of passengers between (and including) the years 1955 and 1960.

**Please write code below. The output should show the standard deviation. You must use the dataframe created in 2a.**
"""

# YOUR CODE HERE: Filter for years 1955-1960 and calculate standard deviation
# Hint: Filter the long format data for years between 1955 and 1960 (inclusive)
# Then calculate the standard deviation of the passenger values
filtered_passengers = air_passengers_long.filter(
    (pl.col("Year") >= 1955) & (pl.col("Year") <= 1960)
)

std_passengers = filtered_passengers["passengers"].std()

print(f"The standard deviation of airline passengers between 1955 and 1960 is: {std_passengers:.2f}")

"""### The standard deviation of airline passengers between (and including) the years 1955 and 1960 is: __________

# Question 3: WHO tuberculosis case data

## 3a. Pivot data

Load the `table2.csv` dataset from the `data/` folder. This contains data for country populations and tuberculosis case metrics. You'll notice that the metrics for `cases` and `population` are in the same column (`count`). Pivot the data so that the metrics for `cases` and `population` are in their own columns.

**Please write code below to pivot the data. The output should be a DataFrame. You must "pivot" the data to receive full credit on this question.**
"""

# Load table2 data
table2 = pl.read_csv("https://raw.githubusercontent.com/philhetzel/opan5510-class12/refs/heads/main/data/table2.csv")

# Display the original data structure
print("Original data:")
print(table2)

# YOUR CODE HERE: Pivot the data so 'cases' and 'population' are separate columns
# Hint: Use pivot() where the values in 'type' column become new column names
# and values come from the 'count' column

table2_wide = table2.pivot(
    index=["country", "year"], # Columns to keep as index
    columns="type",           # Column whose unique values become new columns ('cases', 'population')
    values="count"            # Column containing the values
)

# Display the pivoted dataframe
table2_wide

"""## 3b. Calculate highest cases/population ratio for 1999

Now that you have `cases` and `population` in their own columns, you can perform analysis. Create a new column in this dataset called `ratio` that divides `cases` by `population`. Next, filter the data to only include rows from the `year` of 1999. What is the country with the highest `cases`/`population` ratio?

**Please write code below. You must use the dataframe created in 3a.**
"""

# YOUR CODE HERE:
# 1. Add a 'ratio' column that calculates cases/population
# 2. Filter for year 1999
# 3. Find the country with the highest ratio


table2_with_ratio = table2_wide.with_columns(
    (pl.col("cases") / pl.col("population")).alias("ratio")
)

# Filter for 1999 and find highest ratio
year_1999 = table2_with_ratio.filter(pl.col("year") == 1999)

# Find country with highest ratio
highest_ratio_country = year_1999.sort("ratio", descending=True).head(1)["country"].item()

print("Data for 1999 with ratios:")
print(year_1999)
print(f"\nThe country with the highest cases/population ratio in 1999 is: {highest_ratio_country}")

"""### Answer: The country with the highest cases/population ratio in 1999 is: Brazil__________

## Submission Instructions

1. Complete all code cells above
2. Run all cells to ensure they execute without errors
3. Fill in the answer blanks with your computed values
4. Save and submit your completed notebook
"""